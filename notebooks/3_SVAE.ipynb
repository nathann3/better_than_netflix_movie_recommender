{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "movie",
      "language": "python",
      "name": "movie"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "SVAE.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nathann3/better_than_netflix_movie_recommender/blob/dev/notebooks/3_SVAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ddck2b7JQgH"
      },
      "source": [
        "# Standard Variational Autoencoder (SVAE)\n",
        "\n",
        "The Standard Variational Autoencoder (SVAE), SVAE uses an autoencoder to generate a salient feature representation of users, learning a latent vector for each user. The decoder then takes this latent representation and outputs a probability distribution over all items; we get probabilities of all the movies being watched by each user."
      ],
      "id": "3ddck2b7JQgH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "registered-helmet"
      },
      "source": [
        "# Imports"
      ],
      "id": "registered-helmet"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "developmental-scotland"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "from src.data import make_dataset\n",
        "from src.features import build_features\n",
        "from src.models import SVAE, metrics\n",
        "from tensorflow.python.framework.ops import disable_eager_execution\n",
        "\n",
        "disable_eager_execution()"
      ],
      "id": "developmental-scotland",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liquid-contest"
      },
      "source": [
        "# Prepare Data"
      ],
      "id": "liquid-contest"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "crucial-stable",
        "outputId": "5434a95c-315d-4789-ce09-b2b591c58c53"
      },
      "source": [
        "fp = os.path.join('..', 'data', 'ml-100k.data')\n",
        "make_dataset.download_movie(fp)\n",
        "\n",
        "raw_data = pd.read_csv(fp, sep='\\t', names=['userId', 'movieId', 'rating', 'timestamp'])\n",
        "print(f'Shape: {raw_data.shape}')\n",
        "raw_data.sample(5, random_state=123)"
      ],
      "id": "crucial-stable",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape: (100000, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42083</th>\n",
              "      <td>600</td>\n",
              "      <td>651</td>\n",
              "      <td>4</td>\n",
              "      <td>888451492</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71825</th>\n",
              "      <td>607</td>\n",
              "      <td>494</td>\n",
              "      <td>5</td>\n",
              "      <td>883879556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99535</th>\n",
              "      <td>875</td>\n",
              "      <td>1103</td>\n",
              "      <td>5</td>\n",
              "      <td>876465144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47879</th>\n",
              "      <td>648</td>\n",
              "      <td>238</td>\n",
              "      <td>3</td>\n",
              "      <td>882213535</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36734</th>\n",
              "      <td>113</td>\n",
              "      <td>273</td>\n",
              "      <td>4</td>\n",
              "      <td>875935609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       userId  movieId  rating  timestamp\n",
              "42083     600      651       4  888451492\n",
              "71825     607      494       5  883879556\n",
              "99535     875     1103       5  876465144\n",
              "47879     648      238       3  882213535\n",
              "36734     113      273       4  875935609"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "unable-orchestra",
        "outputId": "449a637d-c5a5-4161-fe28-fe97fa3da1b3"
      },
      "source": [
        "# Binarize the data (only keep ratings >= 4)\n",
        "df_preferred = raw_data[raw_data['rating'] > 3.5]\n",
        "print (df_preferred.shape)\n",
        "df_low_rating = raw_data[raw_data['rating'] <= 3.5]\n",
        "\n",
        "df_preferred.head(10)"
      ],
      "id": "unable-orchestra",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55375, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>298</td>\n",
              "      <td>474</td>\n",
              "      <td>4</td>\n",
              "      <td>884182806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>253</td>\n",
              "      <td>465</td>\n",
              "      <td>5</td>\n",
              "      <td>891628467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>286</td>\n",
              "      <td>1014</td>\n",
              "      <td>5</td>\n",
              "      <td>879781125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>200</td>\n",
              "      <td>222</td>\n",
              "      <td>5</td>\n",
              "      <td>876042340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>122</td>\n",
              "      <td>387</td>\n",
              "      <td>5</td>\n",
              "      <td>879270459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>291</td>\n",
              "      <td>1042</td>\n",
              "      <td>4</td>\n",
              "      <td>874834944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>119</td>\n",
              "      <td>392</td>\n",
              "      <td>4</td>\n",
              "      <td>886176814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>167</td>\n",
              "      <td>486</td>\n",
              "      <td>4</td>\n",
              "      <td>892738452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>299</td>\n",
              "      <td>144</td>\n",
              "      <td>4</td>\n",
              "      <td>877881320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>308</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>887736532</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    userId  movieId  rating  timestamp\n",
              "5      298      474       4  884182806\n",
              "7      253      465       5  891628467\n",
              "11     286     1014       5  879781125\n",
              "12     200      222       5  876042340\n",
              "16     122      387       5  879270459\n",
              "18     291     1042       4  874834944\n",
              "20     119      392       4  886176814\n",
              "21     167      486       4  892738452\n",
              "22     299      144       4  877881320\n",
              "24     308        1       4  887736532"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial-tours",
        "outputId": "e83d689f-fe7e-4e5a-9751-ba76fb468806"
      },
      "source": [
        "# Keep users who clicked on at least 5 movies\n",
        "df = df_preferred.groupby('userId').filter(lambda x: len(x) >= 5)\n",
        "\n",
        "# Keep movies that were clicked on by at least on 1 user\n",
        "df = df.groupby('movieId').filter(lambda x: len(x) >= 1)\n",
        "\n",
        "print(df.shape)"
      ],
      "id": "initial-tours",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(55361, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ordinary-visitor",
        "outputId": "ada49e5d-3e89-4e36-a8cc-8d2aad4e018d"
      },
      "source": [
        "# Obtain both usercount and itemcount after filtering\n",
        "usercount = df[['userId']].groupby('userId', as_index = False).size()\n",
        "itemcount = df[['movieId']].groupby('movieId', as_index = False).size()\n",
        "\n",
        "# Compute sparsity after filtering\n",
        "sparsity = 1. * raw_data.shape[0] / (usercount.shape[0] * itemcount.shape[0])\n",
        "\n",
        "print(\"After filtering, there are %d watching events from %d users and %d movies (sparsity: %.3f%%)\" % \n",
        "      (raw_data.shape[0], usercount.shape[0], itemcount.shape[0], sparsity * 100))"
      ],
      "id": "ordinary-visitor",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After filtering, there are 100000 watching events from 938 users and 1447 movies (sparsity: 7.368%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "english-morris"
      },
      "source": [
        "## Split"
      ],
      "id": "english-morris"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adapted-basketball"
      },
      "source": [
        "unique_users =sorted(df.userId.unique())\n",
        "np.random.seed(123)\n",
        "unique_users = np.random.permutation(unique_users)"
      ],
      "id": "adapted-basketball",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exempt-difference",
        "outputId": "69c31030-9ca7-456a-be91-fe03773e51db"
      },
      "source": [
        "HELDOUT_USERS = 200\n",
        "\n",
        "# Create train/validation/test users\n",
        "n_users = len(unique_users)\n",
        "print(\"Number of unique users:\", n_users)\n",
        "\n",
        "train_users = unique_users[:(n_users - HELDOUT_USERS * 2)]\n",
        "print(\"\\nNumber of training users:\", len(train_users))\n",
        "\n",
        "val_users = unique_users[(n_users - HELDOUT_USERS * 2) : (n_users - HELDOUT_USERS)]\n",
        "print(\"\\nNumber of validation users:\", len(val_users))\n",
        "\n",
        "test_users = unique_users[(n_users - HELDOUT_USERS):]\n",
        "print(\"\\nNumber of test users:\", len(test_users))"
      ],
      "id": "exempt-difference",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique users: 938\n",
            "\n",
            "Number of training users: 538\n",
            "\n",
            "Number of validation users: 200\n",
            "\n",
            "Number of test users: 200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hearing-collective",
        "outputId": "3329b6e7-a122-48e4-ac9e-bf91602e957f"
      },
      "source": [
        "# For training set keep only users that are in train_users list\n",
        "train_set = df.loc[df['userId'].isin(train_users)]\n",
        "print(\"Number of training observations: \", train_set.shape[0])\n",
        "\n",
        "# For validation set keep only users that are in val_users list\n",
        "val_set = df.loc[df['userId'].isin(val_users)]\n",
        "print(\"\\nNumber of validation observations: \", val_set.shape[0])\n",
        "\n",
        "# For test set keep only users that are in test_users list\n",
        "test_set = df.loc[df['userId'].isin(test_users)]\n",
        "print(\"\\nNumber of test observations: \", test_set.shape[0])\n",
        "\n",
        "# train_set/val_set/test_set contain user - movie interactions with rating 4 or 5"
      ],
      "id": "hearing-collective",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training observations:  32491\n",
            "\n",
            "Number of validation observations:  11647\n",
            "\n",
            "Number of test observations:  11223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prescription-spider",
        "outputId": "9c971429-5c5d-410e-d086-299833e8a138"
      },
      "source": [
        "# Obtain list of unique movies used in training set\n",
        "unique_train_items = pd.unique(train_set['movieId'])\n",
        "print(\"Number of unique movies that rated in training set\", unique_train_items.size)"
      ],
      "id": "prescription-spider",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique movies that rated in training set 1346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrapped-companion",
        "outputId": "6ebc3852-1564-45a4-c3c0-ed1f2a43ff1f"
      },
      "source": [
        "# For validation set keep only movies that used in training set\n",
        "val_set = val_set.loc[val_set['movieId'].isin(unique_train_items)]\n",
        "print(\"Number of validation observations after filtering: \", val_set.shape[0])\n",
        "\n",
        "# For test set keep only movies that used in training set\n",
        "test_set = test_set.loc[test_set['movieId'].isin(unique_train_items)]\n",
        "print(\"\\nNumber of test observations after filtering: \", test_set.shape[0])"
      ],
      "id": "wrapped-companion",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of validation observations after filtering:  11562\n",
            "\n",
            "Number of test observations after filtering:  11155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "compatible-paste"
      },
      "source": [
        "# Instantiate the sparse matrix generation for train, validation and test sets\n",
        "# use list of unique items from training set for all sets\n",
        "am_train = build_features.AffinityMatrix(df=train_set, items_list=unique_train_items)\n",
        "\n",
        "am_val = build_features.AffinityMatrix(df=val_set, items_list=unique_train_items)\n",
        "\n",
        "am_test = build_features.AffinityMatrix(df=test_set, items_list=unique_train_items)"
      ],
      "id": "compatible-paste",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "embedded-spell",
        "outputId": "dd8de5d0-522b-4063-9f6f-f86f7387d0cb"
      },
      "source": [
        "# Obtain the sparse matrix for train, validation and test sets\n",
        "train_data, _, _ = am_train.gen_affinity_matrix()\n",
        "print(train_data.shape)\n",
        "\n",
        "val_data, val_map_users, val_map_items = am_val.gen_affinity_matrix()\n",
        "print(val_data.shape)\n",
        "\n",
        "test_data, test_map_users, test_map_items = am_test.gen_affinity_matrix()\n",
        "print(test_data.shape)"
      ],
      "id": "embedded-spell",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(538, 1346)\n",
            "(200, 1346)\n",
            "(200, 1346)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "surface-worship"
      },
      "source": [
        "# Split validation and test data into training and testing parts\n",
        "val_data_tr, val_data_te = make_dataset.numpy_stratified_split(val_data, ratio=0.75, seed=123)\n",
        "test_data_tr, test_data_te = make_dataset.numpy_stratified_split(test_data, ratio=0.75, seed=123)"
      ],
      "id": "surface-worship",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shared-central"
      },
      "source": [
        "# Binarize train, validation and test data\n",
        "train_data = np.where(train_data > 3.5, 1.0, 0.0)\n",
        "val_data = np.where(val_data > 3.5, 1.0, 0.0)\n",
        "test_data = np.where(test_data > 3.5, 1.0, 0.0)\n",
        "\n",
        "# Binarize validation data: training part  \n",
        "val_data_tr = np.where(val_data_tr > 3.5, 1.0, 0.0)\n",
        "# Binarize validation data: testing part (save non-binary version in the separate object, will be used for calculating NDCG)\n",
        "val_data_te_ratings = val_data_te.copy()\n",
        "val_data_te = np.where(val_data_te > 3.5, 1.0, 0.0)\n",
        "\n",
        "# Binarize test data: training part \n",
        "test_data_tr = np.where(test_data_tr > 3.5, 1.0, 0.0)\n",
        "\n",
        "# Binarize test data: testing part (save non-binary version in the separate object, will be used for calculating NDCG)\n",
        "test_data_te_ratings = test_data_te.copy()\n",
        "test_data_te = np.where(test_data_te > 3.5, 1.0, 0.0)"
      ],
      "id": "shared-central",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reserved-speed"
      },
      "source": [
        "# retrieve real ratings from initial dataset \n",
        "\n",
        "test_data_te_ratings=pd.DataFrame(test_data_te_ratings)\n",
        "val_data_te_ratings=pd.DataFrame(val_data_te_ratings)\n",
        "\n",
        "for index,i in df_low_rating.iterrows():\n",
        "    user_old= i['userId'] # old value \n",
        "    item_old=i['movieId'] # old value \n",
        "\n",
        "    if (test_map_users.get(user_old) is not None)  and (test_map_items.get(item_old) is not None) :\n",
        "        user_new=test_map_users.get(user_old) # new value \n",
        "        item_new=test_map_items.get(item_old) # new value \n",
        "        rating=i['rating'] \n",
        "        test_data_te_ratings.at[user_new,item_new]= rating   \n",
        "\n",
        "    if (val_map_users.get(user_old) is not None)  and (val_map_items.get(item_old) is not None) :\n",
        "        user_new=val_map_users.get(user_old) # new value \n",
        "        item_new=val_map_items.get(item_old) # new value \n",
        "        rating=i['rating'] \n",
        "        val_data_te_ratings.at[user_new,item_new]= rating   \n",
        "\n",
        "\n",
        "val_data_te_ratings=val_data_te_ratings.to_numpy()    \n",
        "test_data_te_ratings=test_data_te_ratings.to_numpy()    "
      ],
      "id": "reserved-speed",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "indoor-sheet"
      },
      "source": [
        "# SVAE"
      ],
      "id": "indoor-sheet"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pointed-repeat"
      },
      "source": [
        "INTERMEDIATE_DIM = 200\n",
        "LATENT_DIM = 64\n",
        "EPOCHS = 400\n",
        "BATCH_SIZE = 100"
      ],
      "id": "pointed-repeat",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "incredible-stage"
      },
      "source": [
        "model = SVAE.StandardVAE(n_users=train_data.shape[0], # Number of unique users in the training set\n",
        "                                   original_dim=train_data.shape[1], # Number of unique items in the training set\n",
        "                                   intermediate_dim=INTERMEDIATE_DIM, \n",
        "                                   latent_dim=LATENT_DIM, \n",
        "                                   n_epochs=EPOCHS, \n",
        "                                   batch_size=BATCH_SIZE, \n",
        "                                   k=10,\n",
        "                                   verbose=0,\n",
        "                                   seed=123,\n",
        "                                   drop_encoder=0.5,\n",
        "                                   drop_decoder=0.5,\n",
        "                                   annealing=False,\n",
        "                                   beta=1.0\n",
        "                                   )"
      ],
      "id": "incredible-stage",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "female-pregnancy",
        "outputId": "f2b66ecd-ddaa-4625-b051-49976adfec6a"
      },
      "source": [
        "%%time\n",
        "model.fit(x_train=train_data,\n",
        "          x_valid=val_data,\n",
        "          x_val_tr=val_data_tr,\n",
        "          x_val_te=val_data_te_ratings, # with the original ratings\n",
        "          mapper=am_val\n",
        "          )"
      ],
      "id": "female-pregnancy",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training_v1.py:1246: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 58s, sys: 8.4 s, total: 4min 6s\n",
            "Wall time: 3min 32s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKn8Iq1vgP9H"
      },
      "source": [
        "# Recommend"
      ],
      "id": "EKn8Iq1vgP9H"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "equipped-boards"
      },
      "source": [
        "# Model prediction on the training part of test set \n",
        "top_k =  model.recommend_k_items(x=test_data_tr,k=10,remove_seen=True)\n",
        "\n",
        "# Convert sparse matrix back to df\n",
        "recommendations = am_test.map_back_sparse(top_k, kind='prediction')\n",
        "test_df = am_test.map_back_sparse(test_data_te_ratings, kind='ratings') # use test_data_te_, with the original ratings"
      ],
      "id": "equipped-boards",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5d2_zBCwGL2"
      },
      "source": [
        "## Evaluation metrics"
      ],
      "id": "i5d2_zBCwGL2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMOnHJy9sz9p"
      },
      "source": [
        "# Create column with the predicted movie's rank for each user \n",
        "top_k = recommendations.copy()\n",
        "top_k['rank'] = recommendations.groupby('userId', sort=False).cumcount() + 1  # For each user, only include movies recommendations that are also in the test set"
      ],
      "id": "iMOnHJy9sz9p",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhDysbs0tFkd"
      },
      "source": [
        "precision_at_k = metrics.precision_at_k(top_k, test_df, 'userId', 'movieId', 'rank')\n",
        "recall_at_k = metrics.recall_at_k(top_k, test_df, 'userId', 'movieId', 'rank')\n",
        "mean_average_precision = metrics.mean_average_precision(top_k, test_df, 'userId', 'movieId', 'rank')\n",
        "ndcg = metrics.ndcg(top_k, test_df, 'userId', 'movieId', 'rank')"
      ],
      "id": "rhDysbs0tFkd",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQeRUFCNtKuM",
        "outputId": "45357137-3812-4edc-bc3e-2d588091a383"
      },
      "source": [
        "print(f'Precision: {precision_at_k:.6f}',\n",
        "      f'Recall: {recall_at_k:.6f}',\n",
        "      f'MAP: {mean_average_precision:.6f} ',\n",
        "      f'NDCG: {ndcg:.6f}', sep='\\n')"
      ],
      "id": "GQeRUFCNtKuM",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision: 0.358000\n",
            "Recall: 0.091713\n",
            "MAP: 0.046535 \n",
            "NDCG: 0.354121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkLPL0YCJ5qN"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "1.   Kilol Gupta, Mukunds Y. Raghuprasad, Pankhuri Kumar, A Hybrid Variational Autoencoder for Collaborative Filtering, 2018, https://arxiv.org/pdf/1808.01006.pdf\n",
        "\n",
        "2.   Microsoft SVAE implementation: https://github.com/microsoft/recommenders/blob/main/examples/02_model_collaborative_filtering/standard_vae_deep_dive.ipynb\n"
      ],
      "id": "IkLPL0YCJ5qN"
    }
  ]
}